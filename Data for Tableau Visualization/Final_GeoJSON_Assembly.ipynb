{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frXTTiPkF5PE"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull in life expectancy data\n",
        "life_df = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/main/Clean_Data/le_clean.csv\")"
      ],
      "metadata": {
        "id": "hpg5w2iYl4Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3LX3fCPRG2n"
      },
      "outputs": [],
      "source": [
        "# Pull in gdp data\n",
        "gdp = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/main/Clean_Data/gdp_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBwmQjdMQcRt"
      },
      "outputs": [],
      "source": [
        "# Pull in social security and health system data\n",
        "social = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/main/Clean_Data/Cluster_Analysis_Data/country_social_security_systems-coded.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-YLaj123etF"
      },
      "outputs": [],
      "source": [
        "# Pull in region and subregion data\n",
        "regions = pd.read_csv(\"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X0jhSZL1lVP"
      },
      "outputs": [],
      "source": [
        "# Pull in per capita GDP data\n",
        "per_cap = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/Vivek_Project/Clean_Data/world_bank_gdp_per_capita_clean.csv%20-%20API_NY.GDP.PCAP.CD_DS2_en_csv_v2_4770417.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21QajhwAIb8d"
      },
      "outputs": [],
      "source": [
        "# Pull in alcohol and tobacco data\n",
        "alc_tob = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/Vivek_Project/Clean_Data/alcohol_tobacco_normalized_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alc_tob = alc_tob.rename({'2000 [YR2000': '2000 [YR2000]'}, axis=1)"
      ],
      "metadata": {
        "id": "C4RiwVK-2VWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWyPZsNQLi3Z"
      },
      "outputs": [],
      "source": [
        "# Separate alcohol and tobacco data into separate dataframes\n",
        "alc = alc_tob.loc[alc_tob['Series Name'] == 'Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)']\n",
        "tob = alc_tob.loc[alc_tob['Series Name'] == 'Prevalence of current tobacco use (% of adults)']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull in health expenditure data\n",
        "exp = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/main/Clean_Data/Cluster_Analysis_Data/health_expenditure-clean.csv\")"
      ],
      "metadata": {
        "id": "lKtgQMdYy5KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHGXE3E22QAA"
      },
      "outputs": [],
      "source": [
        "# Pull in list of master country names and codes\n",
        "master = pd.read_csv(\"https://raw.githubusercontent.com/AndrewZinc/Expect_Life/main/Clean_Data/master_country_list/country_profile_urls.csv\")\n",
        "\n",
        "# List of countries in master document\n",
        "country_list = master['country'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T8O5pnD2xEs"
      },
      "outputs": [],
      "source": [
        "# Add country code column to all csvs without country code column\n",
        "for country in country_list:\n",
        "  code_string = master.loc[master['country'] == country, 'country_code'].to_json()\n",
        "  code_name = re.search('[A-Za-z]+', code_string).group(0)\n",
        "  gdp.loc[gdp['Country Name'] == country, 'Country Code'] = code_name\n",
        "  social.loc[social['country'] == country, 'Country Code'] = code_name\n",
        "  alc.loc[alc_tob['Country Name'] == country, 'Country Code'] = code_name\n",
        "  tob.loc[alc_tob['Country Name'] == country, 'Country Code'] = code_name\n",
        "  exp.loc[exp['country'] == country, 'Country Code'] = code_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zy_QUd_mgdP"
      },
      "outputs": [],
      "source": [
        "# Correct null value\n",
        "tob.at[1, 'Country Code'] = 'ALB'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B-sJM9ItukF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5jRdlyOg5Oy"
      },
      "outputs": [],
      "source": [
        "# Load existing geojson point data\n",
        "with open('countries (1).geojson') as f:\n",
        "  data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i89t3EnVSQx7"
      },
      "outputs": [],
      "source": [
        "# Add life expectancy and other metrics to geojson data\n",
        "import re\n",
        "\n",
        "for i in range(0,len(data['features'])):\n",
        "  country_code = data['features'][i]['properties']['ISO_A3']\n",
        "  for j in range(2000,2020):\n",
        "    try:\n",
        "      continent = regions.loc[regions['alpha-3'] == country_code, 'region'].to_json()\n",
        "      continent = re.search(':\"\\D+', continent).group(0)\n",
        "      continent = continent[2:-2]\n",
        "      data['features'][i]['properties']['continent'] = continent\n",
        "    except:\n",
        "      data['features'][i]['properties']['continent'] = ''\n",
        "    try:\n",
        "      sub_region = regions.loc[regions['alpha-3'] == country_code, 'sub-region'].to_json()\n",
        "      sub_region = re.search(':\"\\D+', sub_region).group(0)\n",
        "      sub_region = sub_region[2:-2]\n",
        "      data['features'][i]['properties']['sub-region'] = sub_region\n",
        "    except:\n",
        "      data['features'][i]['properties']['sub-region'] = ''   \n",
        "    try:\n",
        "      soc_string = social.loc[social['Country Code'] == country_code, 'system_type'].to_json()\n",
        "      soc_string = re.search(\"\\[.+\\]\", soc_string).group(0)\n",
        "      social_sys = soc_string[1:-1]\n",
        "      data['features'][i]['properties']['system'] = social_sys\n",
        "    except:\n",
        "      data['features'][i]['properties']['system'] = ''\n",
        "    try:\n",
        "      depth_string = social.loc[social['Country Code'] == country_code, 'sss_depth'].to_json()\n",
        "      depth = depth_string[-2]\n",
        "      data['features'][i]['properties']['system_depth'] = int(depth)\n",
        "    except:\n",
        "      data['features'][i]['properties']['system_depth'] = ''\n",
        "    try:\n",
        "      govt = exp.loc[social['Country Code'] == country_code, 'govt_he'].to_json()\n",
        "      govt_exp_val = float(re.search('\\d+\\.\\d+', govt).group(0))\n",
        "      data['features'][i]['properties']['govt'] = round(float(govt_exp_val),2)\n",
        "    except:\n",
        "      data['features'][i]['properties']['govt'] = 0\n",
        "    try:\n",
        "      priv = exp.loc[social['Country Code'] == country_code, 'private_he'].to_json()\n",
        "      priv_exp_val = float(re.search('\\d+\\.\\d+', priv).group(0))\n",
        "      data['features'][i]['properties']['priv'] = round(float(priv_exp_val),2)\n",
        "    except:\n",
        "      data['features'][i]['properties']['priv'] = 0    \n",
        "    yr_string = str(j)\n",
        "    try:\n",
        "      expectancy = life_df.loc[life_df['Country Code'] == country_code, f'{yr_string}']\n",
        "      expectancy = expectancy.to_json()\n",
        "      expectancy = re.search(\"\\d\\d\\.\\d\\d\", expectancy).group(0)\n",
        "      expectancy = float(expectancy)\n",
        "      data['features'][i]['properties'][f'life_expectancy [YR{yr_string}]'] = round(float(expectancy),2)\n",
        "    except:\n",
        "      data['features'][i]['properties'][f'life_expectancy [YR{yr_string}]'] = 0\n",
        "    try:\n",
        "      gdp_string = gdp.loc[gdp['Country Code'] == country_code, f'{yr_string}'].to_json()\n",
        "      gdp_val = float(re.search('\\d+\\.\\d+', gdp_string).group(0))\n",
        "      data['features'][i]['properties'][f'gdp [YR{yr_string}]'] = round(float(gdp_val),2)\n",
        "    except:\n",
        "      data['features'][i]['properties'][f'gdp [YR{yr_string}]'] = 0\n",
        "    try:\n",
        "      gdp_cap_string = per_cap.loc[per_cap['Country Code'] == country_code, f'{yr_string}'].to_json()\n",
        "      gdp_cap_val = float(re.search('\\d+\\.\\d+', gdp_cap_string).group(0))\n",
        "      data['features'][i]['properties'][f'gdp_pcap [YR{yr_string}]'] = round(float(gdp_cap_val),2)\n",
        "    except:\n",
        "      data['features'][i]['properties'][f'gdp_pcap [YR{yr_string}]'] = 0\n",
        "    try:\n",
        "      alc_string = alc.loc[alc['Country Code'] == country_code, f'{yr_string} [YR{yr_string}]'].to_json()\n",
        "      alc_level = float(re.search('\\d+\\.\\d+', alc_string).group(0))\n",
        "      data['features'][i]['properties'][f'alc [YR{yr_string}]'] = round(float(alc_level),2)\n",
        "    except:\n",
        "      data['features'][i]['properties'][f'alc [YR{yr_string}]'] = 0\n",
        "    try:\n",
        "      tob_string = tob.loc[tob['Country Code'] == country_code, f'{yr_string} [YR{yr_string}]'].to_json()\n",
        "      tob_level = float(re.search('\\d+\\.\\d+', tob_string).group(0))\n",
        "      data['features'][i]['properties'][f'tob [YR{yr_string}]'] = round(float(tob_level),2)\n",
        "    except:\n",
        "      data['features'][i]['properties'][f'tob [YR{yr_string}]'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoRbvccohF4F"
      },
      "outputs": [],
      "source": [
        "# # # Write GeoJSON file with new data for tableau visualization\n",
        "with open('float_file_round.geojson', 'w') as f:\n",
        "   f.write(json.dumps(data))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
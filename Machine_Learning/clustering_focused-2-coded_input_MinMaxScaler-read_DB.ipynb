{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import plotly.express as px\n",
    "from functools import reduce\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, FastICA\n",
    "from sklearn.cluster import AgglomerativeClustering, Birch, KMeans, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdfed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the config from the .env file\n",
    "load_dotenv()\n",
    "MONGODB_URI = os.environ['MONGODB_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99538c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database engine\n",
    "client = MongoClient(MONGODB_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the project db\n",
    "db = client['ExpectLife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f82763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a reference to the data collection\n",
    "data = db['clustering_final_system_coded_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the collection\n",
    "combined_df = pd.DataFrame(list(data.find()))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caad966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the database id data and refresh the index\n",
    "combined_df = combined_df.drop(['_id'], axis=1)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the country names.  Apply the country names as the new index for later merging.\n",
    "country_df = pd.DataFrame()\n",
    "country_df['country'] = combined_df['country']\n",
    "country_df = country_df.set_index('country', drop=False)\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the DataFrame index to the country names to get them out of the way\n",
    "combined_df = combined_df.set_index('country')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f6a41",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f499d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies() to create variables for text features.\n",
    "encode_df = pd.get_dummies(combined_df, columns=['s1','s2','s3','s4','s5'])\n",
    "encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the column labels so they can be reapplied after data scaling\n",
    "col_names = encode_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13769c5d",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ce387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with MinMaxScaler().\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "encode_scaled_nda = scaler.fit_transform(encode_df)\n",
    "encode_scaled_nda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled-encoded data back to a DataFrame (nda = Numpy Data Array)\n",
    "\n",
    "scale_encode_df = pd.DataFrame(encode_scaled_nda, index=encode_df.index)\n",
    "scale_encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the column labels to ensure the data is properly identified\n",
    "scale_encode_df = scale_encode_df.set_axis(col_names, axis=1)\n",
    "scale_encode_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61895163",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters with starter values\n",
    "nc =10   #:n_clusters\n",
    "rs = 42  #:random_state\n",
    "ms = 20  #:min_samples\n",
    "eps = 0.65 #:eps\n",
    "n_comp = 10 #:n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to the principal components.\n",
    "\n",
    "pca = PCA(n_components=n_comp)\n",
    "#pca = IncrementalPCA(whiten=True)\n",
    "\n",
    "# Get principal components for the demographics data\n",
    "\n",
    "demo_pca = pca.fit_transform(encode_scaled_nda)\n",
    "demo_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fadd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the principal components.\n",
    "columnz =[]\n",
    "\n",
    "for i in range(1,n_comp+1):\n",
    "    columnz.append('pc'+str(i))\n",
    "\n",
    "pcs_df = pd.DataFrame(data=demo_pca, columns=columnz, index=combined_df.index)\n",
    "#pcs_df = pd.DataFrame(data=demo_pca, index=combined_df.index) # IncrementalPCA\n",
    "pcs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a5128",
   "metadata": {},
   "source": [
    "## Compute an Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "inertia = []\n",
    "k= list(range(1,15))\n",
    "\n",
    "# Calculate the inertia for a range of k values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=rs)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "# Create the elbow curve\n",
    "elbow_data = {'k': k, 'inertia': inertia}\n",
    "elbow_df = pd.DataFrame(elbow_data)\n",
    "\n",
    "elbow_df.hvplot(x='k', y='inertia', xticks=k, title='Elbow Curve')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters for the models below\n",
    "nc = 6   #:n_clusters\n",
    "rs = 42  #:random_state\n",
    "ms = 20  #:min_samples\n",
    "eps = 0.05 #:eps\n",
    "n_comp = 8 #:n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f54f91f",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model.\n",
    "model = KMeans(n_clusters=nc, random_state=rs)\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "km_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(km_pcs_df)\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(km_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "km_pcs_df['class'] = model.labels_\n",
    "km_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fef08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_scenc_df = scale_encode_df.copy()\n",
    "pca_scenc_df = pca_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_scenc_df, km_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a01052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65e351",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc38a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = AgglomerativeClustering(n_clusters=nc, linkage='complete')\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "ac_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model - Make predictions\n",
    "pred = model.fit_predict(ac_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "ac_pcs_df['class'] = model.labels_\n",
    "ac_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_ac_scenc_df = scale_encode_df.copy()\n",
    "pca_ac_scenc_df = pca_ac_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_ac_scenc_df, ac_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7626d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15b12832",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering - Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4afbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = AgglomerativeClustering(n_clusters=nc)\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "acw_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model - Make predictions\n",
    "pred = model.fit_predict(acw_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "acw_pcs_df['class'] = model.labels_\n",
    "acw_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_acw_scenc_df = scale_encode_df.copy()\n",
    "pca_acw_scenc_df = pca_acw_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_acw_scenc_df, acw_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e154715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91dfc958",
   "metadata": {},
   "source": [
    "## BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe779ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Birch(threshold=0.01, branching_factor=45, n_clusters=nc)\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "b_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model - Make predictions\n",
    "pred = model.fit_predict(b_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "b_pcs_df['class'] = model.labels_\n",
    "b_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe000539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_b_scenc_df = scale_encode_df.copy()\n",
    "pca_b_scenc_df = pca_b_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_b_scenc_df, b_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7513aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d551bef",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb569868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = SpectralClustering(n_clusters=nc, eigen_solver='arpack', assign_labels='cluster_qr')\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "sc_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model - Make predictions\n",
    "pred = model.fit_predict(sc_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "sc_pcs_df['class'] = model.labels_\n",
    "sc_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_sc_scenc_df = scale_encode_df.copy()\n",
    "pca_sc_scenc_df = pca_sc_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_sc_scenc_df, sc_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b477b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4119d9",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = GaussianMixture(n_components=n_comp, covariance_type='diag', n_init=3, max_iter=200, init_params='random_from_data')\n",
    "\n",
    "# Create a copy of the pcs_df for processing below\n",
    "g_pcs_df = pcs_df.copy()\n",
    "\n",
    "# Fit the model - Make predictions\n",
    "pred = model.fit_predict(g_pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "g_pcs_df['class'] = pred\n",
    "g_pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant columns\n",
    "pca_g_scenc_df = scale_encode_df.copy()\n",
    "pca_g_scenc_df = pca_g_scenc_df.drop(['both_sexes_lex','female_lex','male_lex','GDP(M$)','daily calories (2018)', 'daily plant protein (g  2013)', 'daily animal protein (g  2013)', 'population','sss_depth','govt_he','private_he','govt_he_gdp','tot_alcohol_consumption','tobacco_use_%'], axis=1)\n",
    "\n",
    "# Create a new DataFrame including predicted clusters and demographic features.\n",
    "frames = [country_df, combined_df, pca_g_scenc_df, g_pcs_df]\n",
    "clustered_df = pd.concat(frames, axis=1, join='outer')\n",
    "clustered_df.index = encode_df.index\n",
    "\n",
    "# Drop the string column\n",
    "clustered_df = clustered_df.drop(['s1','s2','s3','s4','s5'], axis=1)\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f633e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Scatter with the scale_encode_df data and the clusters\n",
    "fig = px.scatter_3d(clustered_df, x='sss_depth', y='population', z='govt_he', color='class', hover_name='country', hover_data=['both_sexes_lex','population','GDP(M$)'], width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54430d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot.\n",
    "sizez = clustered_df['sss_depth'] * 30\n",
    "\n",
    "clustered_df.hvplot.scatter(x='class', y='both_sexes_lex', size=sizez, hover_cols=['country'], line_color='#c994c7', hover_line_color='magenta', by='class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
